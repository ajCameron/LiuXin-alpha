#!/usr/bin/env python
# vim:fileencoding=UTF-8:ts=4:sw=4:sta:et:sts=4:a

"""
Metadata container for a book.

Intended to store all the data from the database about an individual book.
Including the ids of the associated entities on the database (if needed).

This object is intended to store any data which might be added to the database about an object. Including the ids of
the corresponding rows on the database.
The standard container is an ordered dictionary - keyed by the item value and valued with the item id
- for example, say the title had the tags 'cyberpunk' & 'alternative-reality'. The tag-container might have the form
{'cyberpunk':238, 'alternative-reality':None}

There are classes of object where type is relevant as well as the raw information.
For example, creators, which can have various sub-types (author, illustrator e.t.c).
These are stored are the top level in their own container and each has their own ordered dictionary
- but can be accessed as one block by some methods.
MD.authors will produce the authors dict.
and MD.creators will throw back an dict of OrderDicts, keyed with the role and values with that role's OrderedDict.
Similarly, for identifiers and internal identifiers.

"""


from __future__ import division, absolute_import, print_function, annotations

import os
import re
import pprint
from collections import OrderedDict
from copy import deepcopy
from numbers import Number

from LiuXin_alpha.constants import ALLOWED_DOC_TYPES
from LiuXin_alpha.constants import check_image_tuple

# from LiuXin.databases.row_collection import RowCollection
#
# from LiuXin.exceptions import InputIntegrityError
# from LiuXin.exceptions import LogicalError
# from LiuXin.exceptions import DatabaseIntegrityError
#
# from LiuXin.file_formats.chardet import force_encoding
#
# from LiuXin.metadata import check_isbn
# from LiuXin.metadata import string_to_authors
# from LiuXin.metadata import authors_to_sort_string
# from LiuXin.metadata.book.base import calibreMetadata
# from LiuXin.metadata.constants import CREATOR_DROP_REGEX_SET
# from LiuXin.metadata.constants import CREATOR_CATEGORIES
# from LiuXin.metadata.constants import CREATOR_TYPES
# from LiuXin.metadata.constants import CREATOR_TYPE_CAT_DIR
# from LiuXin.metadata.constants import EXTERNAL_EBOOK_ID_SCHEMA
# from LiuXin.metadata.constants import EXTERNAL_EBOOK_REKEY_SCHEME
# from LiuXin.metadata.constants import INTERNAL_EBOOK_ID_SCHEMA
# from LiuXin.metadata.constants import INTERNAL_EBOOK_REKEY_SCHEME
# from LiuXin.metadata.constants import METADATA_EXPLANATIONS
# from LiuXin.metadata.constants import METADATA_NULL_VALUES
# from LiuXin.metadata.metadata_standardize import standardize_id_name
# from LiuXin.metadata.metadata_standardize import standardize_creator_category
# from LiuXin.metadata.metadata_standardize import standardize_lang
# from LiuXin.metadata.metadata_standardize import standardize_internal_id_name
# from LiuXin.metadata.metadata_standardize import standardize_rating_type
# from LiuXin.metadata.metadata_standardize import standardize_tag
#
# from LiuXin.utils.localization import trans as _
# from LiuXin.utils.logger import default_log
#
# # Py2/Py3 compatibility layer
# from LiuXin.utils.lx_libraries.liuxin_six import six_string_types
# from LiuXin.utils.lx_libraries.liuxin_six import dict_iterkeys as iterkeys
# from LiuXin.utils.lx_libraries.liuxin_six import dict_iteritems as iteritems
# from LiuXin.utils.lx_libraries.liuxin_six import six_unicode
#



from LiuXin_alpha.metadata.identifiers import clean_id_key, clean_id_value

__author__ = "Cameron"
__license__ = "GPL v3"
__object_version__ = "3.0.0"


class AutogeneratedCreator(Exception):
    pass


# TODO: user_metadata - need a way to determine which columns of a user defined table should be automatically included.


class MetaData:
    """
    A class representing the MetaData of an object.

    The standard metadata fields are available as attributes of this object. You can also hang arbitrary attributes on
    it.
    Though this is often a bad idea.

    The :method is_null: cam be used to checks and see if the field is null.
    """

    @classmethod
    def from_calibre(cls, calibre_md):
        """
        Returns a MetaData class object from a calibre metadata object.

        (or something with the same API).
        :param calibre_md: A calibre metadata object to initialize from
        :return:
        """
        title = None if not hasattr(calibre_md, "title") else calibre_md.title
        authors = None if not hasattr(calibre_md, "authors") else calibre_md.authors

        md = cls(title, authors)

        # Transfer author sort - if there is both an author sort field and a creator sort field then prefer the creator
        # sort over the author sort
        if hasattr(calibre_md, "author_sort") and hasattr(calibre_md, "creator_sort"):
            md.creator_sort = calibre_md.creator_sort if calibre_md.creator_sort else calibre_md.author_sort
        elif hasattr(calibre_md, "author_sort") and not hasattr(calibre_md, "creator_sort"):
            md.creator_sort = calibre_md.author_sort
        elif not hasattr(calibre_md, "author_sort") and hasattr(calibre_md, "creator_sort"):
            md.creator_sort = calibre_md.creator_sort
        else:
            pass

        # Transfer over the pubdate
        if hasattr(calibre_md, "pubdate"):
            md.pubdate = calibre_md.pubdate
        elif hasattr(calibre_md, "pub_date"):
            md.pubdate = calibre_md.pub_date

        # Try and transfer over the identifiers
        # EXTERNAL_EBOOK_REKEY_SCHEME is a dictionary keyed with a frozen set of known identifier names and valued with
        # the common identifier type that those identifiers should be mapped to. Trying to identify each of those id
        # types and copy them across
        for id_set in EXTERNAL_EBOOK_REKEY_SCHEME.keys():
            for id_name in id_set:
                if hasattr(calibre_md, id_name):
                    setattr(md, id_name, getattr(calibre_md, id_name))
        for id_set in INTERNAL_EBOOK_REKEY_SCHEME.keys():
            for id_name in id_set:
                if hasattr(calibre_md, id_name):
                    setattr(md, id_name, getattr(calibre_md, id_name))
        if hasattr(calibre_md, "get_identifiers"):
            calibre_md_identifiers = calibre_md.get_identifiers()
            md.set_identifiers(calibre_md_identifiers)

        # Transfer over the application_id
        if hasattr(calibre_md, "application_id"):
            md.application_id = calibre_md.application_id
        if hasattr(calibre_md, "applicationid"):
            md.application_id = calibre_md.applicationid

        # Transfer over the languages
        if hasattr(calibre_md, "language"):
            md.language = calibre_md.language
        if hasattr(calibre_md, "languages"):
            md.languages = calibre_md.languages

        # Transfer the producer - book producer is mapped to producer
        if hasattr(calibre_md, "book_producer"):
            md.producer = calibre_md.book_producer
        if hasattr(calibre_md, "producer"):
            md.producer = calibre_md.producer

        # Transfer the cover
        if hasattr(calibre_md, "cover"):
            md.cover = calibre_md.cover

        return md

    def __init__(self, title=None, authors=None, other=None):
        """
        If the rest MetaData object is passed in, it's values will be overwritten by the given title and authors.
        If you want to pass in cretors who are not authors, use the add_creator methods
        :param title:
        :param authors:
        :param other:
        :return:
        """
        _data = deepcopy(METADATA_NULL_VALUES)

        # The __setattr__ and __getattr__ methods will be overridden - thus sorting the data somewhere else
        object.__setattr__(self, "_data", _data)

        # Needed to that open files can be made safe
        object.__setattr__(self, "_files_for_cleanup", [])

        # Do this first, so that the title and authors, if provided, will write over it
        if other is not None:
            self.smart_update(other)

        if title is not None:
            self.__setattr__("title", title)

        # Todo: Find string_to_authors - use it here
        if authors is not None:
            # If authors is just a string, tokenized it on the & and add all the authors
            if isinstance(authors, six_string_types):
                author_tokens = authors.split("&")
                for author in author_tokens:
                    self.__setattr__("authors", author)
            elif isinstance(authors, (tuple, list)):
                for author in authors:
                    self.__setattr__("authors", author)
            elif isinstance(authors, (dict, OrderedDict)):
                raise NotImplementedError("Use another method to add row information")
            else:
                raise NotImplementedError("This possibility has not been adequately addressed")

    def setattr(self, key, value):
        """
        External wrapper for the __setattr__ method.
        :param key:
        :param value:
        :return:
        """
        self.__setattr__(key, value)

    def __setattr__(self, key, value):
        """
        Writes data into the internal _data dictionary - allows for a dot interface.
        Arbitrary attributes can be hung on this class. Use with care.
        When you use __setattr__ for a category which can have multiple entries (which is most of them - with the
        exception of title), by default the value is added to the end of the collection. To overwrite, set it null
        and then add.
        key is transformed with key.lower().strip() before anything else is done - thus keys which are only different
        up to capitalization and surrounding whitespace will end up the same.
        :param key:
        :param value:
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        key = key.lower().strip()
        if isinstance(value, six_string_types):
            value = value.strip()

        # Check that the user isn;t trying to set fields which should not be directly set
        if key in ["identifiers", "internal_identifers", "creators"]:
            err_str = "Attribute cannot be directly set - please use the specialized set methods."
            err_str = default_log.log_variables(err_str, "ERROR", ("key", key))
            raise AttributeError(err_str)

        # Dealing with fields that expect a single entry
        if key.lower() in ["comment", "comments"]:
            value = value.strip()
            if value not in _data["comments"]:
                _data["comments"][value] = None
                return
            else:
                return

        if key.lower() == "cover_data":
            if len(value) != 2:
                err_str = "Warning - cover data not of recognized form.\n"
                raise InputIntegrityError(err_str)
            _data["cover_data"][value] = None
            return

        creator_key = standardize_creator_category(key, logging=False)
        if creator_key is not None:
            if creator_key in _data:
                if isinstance(value, six_string_types):

                    # Check to see if the passed values is one of those that should be ignored
                    for creator_re in CREATOR_DROP_REGEX_SET:
                        if re.match(creator_re, value):
                            return

                    for author in string_to_authors(value):
                        _data[creator_key][author] = None

                elif isinstance(value, (tuple, list)):
                    for v in value:
                        # Filter out the values of v which are in the autogenerated drop regex list
                        try:
                            for creator_re in CREATOR_DROP_REGEX_SET:
                                if re.match(creator_re, v):
                                    raise AutogeneratedCreator
                        except AutogeneratedCreator:
                            continue
                        else:
                            _data[creator_key][v] = None
                elif value is None:
                    pass
                else:
                    raise NotImplementedError("value type not recognized - type(value): {}".format(type(value)))
                return
            elif creator_key not in _data:
                _data[creator_key] = OrderedDict()
                _data[creator_key][value] = None
                return
            else:
                raise NotImplementedError("This position should never be reached")

        # Creator sort is just a string
        if key.lower() == "creator_sort":
            _data["creator_sort"] = value
            return

        if key.lower() == "custom_fields_keys":
            raise NotImplementedError

        if key.lower() == "custom_fields":
            raise NotImplementedError

        if key.lower() == "doc_type":
            _data["doc_type"] = value
            return

        if key.lower() == "genre":
            _data["genre"][value] = None
            return

        if key.lower() == "filename":
            _data["filename"].append(value)
            return

        if key.lower() == "filepath":
            _data["filepath"].append(value)
            return

        if key.lower() == "files":
            _data["files"][value] = None
            return

        identifiers_key = standardize_id_name(key, logging=False)
        if identifiers_key is not None:
            if identifiers_key in _data:
                _data[identifiers_key][value] = None
                return
            elif identifiers_key not in _data:
                _data[identifiers_key] = OrderedDict()
                _data[identifiers_key][value] = None
                return
            else:
                raise NotImplementedError

        if key.lower() == "imprint":
            _data["imprint"][value] = None
            return

        internal_ids_key = standardize_internal_id_name(key, logging=False)
        if internal_ids_key is not None:
            if internal_ids_key in _data:
                _data[internal_ids_key][value] = None
                return
            elif internal_ids_key not in _data:
                _data[internal_ids_key] = OrderedDict()
                _data[internal_ids_key][value] = None
                return
            else:
                raise NotImplementedError

        if key.lower() == "language":
            lang_value = standardize_lang(value)
            if lang_value:
                _data["language"] = lang_value
            else:
                # Failed to standardize the language string - just writing it and continuing
                _data["language"] = value
                return

        if key.lower() == "languages":
            if isinstance(value, six_string_types):
                _data["languages"].append(value)
                return
            elif hasattr(value, "__iter__"):
                for val in value:
                    _data["languages"].append(val)
                return
            else:
                raise NotImplementedError("Unrecognized value type - {}".format(type(value)))

        if key.lower() == "languages_available":
            lang_value = standardize_lang(value)
            if lang_value not in _data["languages_available"]:
                _data["languages_available"][lang_value] = None
                return
            else:
                return

        if key.lower() == "last_modified":
            _data["last_modified"] = value
            return

        if key.lower() == "metadata_date":
            _data["metadata_date"] = value
            return

        if key.lower() == "metadata_language":
            _data["metadata_language"] = standardize_lang(value)
            return

        if key.lower() in ["note", "notes"]:
            if value not in _data["notes"]:
                _data["notes"][value] = None
                return
            else:
                return

        if key.lower() == "page_count":
            _data["page_count"] = value

        if key.lower() == "pubdate":
            _data["pubdate"] = value
            return

        if key.lower() == "publisher":
            if isinstance(value, six_string_types):
                _data["publisher"][value] = None
            elif isinstance(value, list):
                for pub_name in value:
                    _data["publisher"][pub_name] = None
            return

        if key.lower() == "ratings":

            if isinstance(value, (tuple, list)):
                if len(value) == 2:
                    o_value = value[0]
                    st_value = standardize_rating_type(o_value)
                    if st_value is not None:
                        _data["ratings"][st_value] = value[1]
                    elif st_value is None:
                        err_str = "Unable to match rating type to the known rating types.\n"
                        default_log.log_variables(
                            err_str,
                            "WARNING",
                            ("rating_type", o_value),
                            ("value", value),
                        )
                        _data["ratings"][o_value] = value[1]
                    else:
                        raise NotImplementedError("This position should never be reached")
                else:
                    err_str = "Rating not properly formed"
                    default_log.log_variables(err_str, "WARNING", ("value", value))

            elif isinstance(value, dict):
                for rating_type in value:
                    s_rating_type = standardize_rating_type(rating_type)
                    rating = value[rating_type]
                    if s_rating_type is not None:
                        _data["ratings"][s_rating_type] = rating
                    elif s_rating_type is None:
                        err_str = "Unable to match rating type to the known rating types.\n"
                        default_log.log_variables(err_str, "WARNING", ("rating_type", rating_type))
                        _data["ratings"][rating_type] = rating
                    else:
                        raise NotImplementedError("This position should never be reached")
            else:
                raise NotImplementedError("This position should never be reached.")
            return

        if key.lower() == "rights":
            _data["rights"] = value
            return

        if key.lower() == "series":
            _data["series"][value] = None
            # If this was the first series set, and there is a float series index stored as calibre_series_index then
            # assign that series index to this series
            # (this is so you can make a call of md.series_index = something, then md.series = something_else and it'll
            # group the series and the series index properly
            if len(_data["series"]) == 1 and "calibre_series_index" in _data:
                _data["series_index"][value] = _data["calibre_series_index"]
                del _data["calibre_series_index"]
            return

        if key.lower() == "series_index":
            # LiuXin supports the same work being in multiple series at the same time - thus the series the index
            # corresponds to must be specified (by name).
            # series_index thus takes a tuple or a list - the first element being the name of the series and the
            # second element being the series_index
            if isinstance(value, (tuple, list)):
                assert len(value) == 2
                _data["series_index"][value[0]] = value[1]
                return
            elif isinstance(value, (six_string_types, Number)):
                # If there is only one series set then set the series to be that
                if len(_data["series"]) == 1:
                    _data["series_index"][_data["series"].keys()[0]] = value
                else:
                    # Cache for later processing
                    _data["calibre_series_index"] = value
                return

        if key.lower() == "subject":
            if isinstance(value, six_string_types):
                _data["subject"][value] = None
            elif isinstance(value, (list, set, tuple)):
                for v in value:
                    _data["subject"][v] = None
            else:
                raise NotImplementedError
            return

        if key.lower() in ["synopsis", "synopses"]:
            if isinstance(value, six_string_types):
                _data["synopses"][value] = None
            elif hasattr(value, "__iter__"):
                value = deepcopy(value)
                for synopsis in value:
                    _data["synopses"][synopsis] = None
            else:
                raise NotImplementedError
            return

        if key.lower() in ["tag", "tags"]:

            # Split on semi-colon separations
            if isinstance(value, six_string_types):
                tag_vals = value.split(";")
                for tag_val in tag_vals:
                    tag_val = tag_val.strip()
                    _data["tags"][tag_val] = None

            elif isinstance(value, (list, set, tuple)):
                for v in value:
                    _data["tags"][v] = None

            else:
                err_str = "Couldn't parse the given type of value into tags\n"
                err_str += "type(value): {}\n".format(type(value))
                err_str += "value: {}".format(value)
                raise NotImplementedError(err_str)
            return

        if key.lower() == "timestamp":
            _data["timestamp"] = value
            return

        if key.lower() in ["title_sort", "titlesort"]:
            _data["title_sort"] = value
            return

        if key.lower() == "user_metadata":
            raise NotImplementedError

        if key.lower() == "wordcount":
            _data["wordcount"] = value
            return

        # If the method hasn't been specially handled, add the _data anyway
        _data[key] = value
        return

    def get(self, field, default=None):
        """
        Interface to the __getattr__ method, with a default for if the attribute doesn't exist.
        calibre emulation.
        :param field:
        :param default:
        :return:
        """
        try:
            return self.__getattr__(field)
        except AttributeError:
            return default

    def get_extra(self, field, default=None):
        """
        Tries to return the field from the user metadata, with a default in case it doesn't succeed.
        calibre emulation.
        :param field:
        :param default:
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        if field in iterkeys(_data["user_metadata"]):
            try:
                return _data["user_metadata"][field]
            except AttributeError:
                return default
        raise AttributeError("Metadata object has no attribute named: " + repr(field))

    def read_creators(self, creators_dict):
        """
        Add creators to the metadata object in the form of a dict keyed with the role of the creator and values with
        either the creator name or an itterable of creator names.
        :param creators_dict:
        :return:
        """
        for creator_role in creators_dict:
            self.__setattr__(creator_role, creators_dict[creator_role])

    def direct_get(self, item):
        """
        Directed access the data _dict.
        :param item:
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        if item in _data.keys():
            return _data[item]
        raise AttributeError("Metadata object has no attribute named: " + repr(item))

    def __getattr__(self, item):
        """
        Allows a dot interface to the MetaData class.
        Most attributes are stored as an OrderedDict - this method returns a copy of the KEYS of this dictionary as a
        list.
        Modifying this list won't do anything.
        Calling creators will get a dictionary keyed with the role of the creators and valued with a list of their
        names.
        This is for calibre compatibility reasons.
        If you want all the data available call :meth get_dict:
        :param item:
        :return:
        """
        _data = object.__getattribute__(self, "_data")

        # Call to creators returns a dictionary keyed by the creator types and valued with an index of the creators
        # Other calls should be made to get the embedded row data as well
        if item.lower() == "creators":
            # All creators are requested - build the directory and return it
            creators_dict = dict()
            for creator_role in CREATOR_CATEGORIES:
                if creator_role in _data:
                    creators_dict[creator_role] = deepcopy([creator for creator in _data[creator_role].keys()])
            return creators_dict
        creator_item = standardize_creator_category(item)
        if creator_item is not None:
            if creator_item in _data:
                return _data[creator_item]
            else:
                _data[creator_item] = OrderedDict()
                return _data[creator_item]

        if item.lower() == "identifiers":
            ids_dict = dict()
            for id_type in EXTERNAL_EBOOK_ID_SCHEMA:
                if id_type in _data:
                    ids_dict[id_type] = deepcopy([id_val for id_val in _data[id_type].keys()])
            return deepcopy(ids_dict)
        external_id_name = standardize_id_name(item)
        if external_id_name is not None:
            if external_id_name in _data:
                return _data[external_id_name]
            else:
                _data[external_id_name] = set()
                return _data[external_id_name]

        if item.lower() == "internal_identifiers":
            ids_dict = dict()
            for id_type in INTERNAL_EBOOK_ID_SCHEMA:
                if id_type in _data:
                    ids_dict[id_type] = deepcopy([id_val for id_val in _data[id_type].keys()])
            return deepcopy(ids_dict)
        internal_id_name = standardize_internal_id_name(item)
        if internal_id_name is not None:
            if internal_id_name in _data:
                return _data[internal_id_name]
            else:
                _data[internal_id_name] = set()
                return _data[internal_id_name]

        # Check to see if the attribute is in the creator types - if it is then return the appropriate entry
        if item in CREATOR_TYPES:
            return _data[CREATOR_TYPE_CAT_DIR[item]]

        # Return the best guess if they're asking for comment
        if item in ["comment", "comments"]:
            return deepcopy(_data["comments"])

        # Probably want the title sort
        if item in ["titlesort", "title_sort"]:
            return deepcopy(_data["title_sort"])

        if item in _data.keys():
            current_val = _data[item]
            return deepcopy(current_val)

        # The attribute has not been set - attribute error
        err_str = "Unable to recognize attribute in LiuXin Metadata. Returning False.\n"
        err_str = default_log.log_variables(err_str, "INFO", ("item", item))
        raise AttributeError(err_str)

    def __getitem__(self, item):
        """
        Allows a dictionary like interface, directly to the _data dictionary.
        Use with care - direct access bypasses the usual set methods, so you should make sure to leave the MetaData in
        a consistent state when you finish.
        :param item:
        :return:
        """
        try:
            _data = object.__getattribute__(self, "_data")
            return _data[item]
        except KeyError:
            raise AttributeError("MetaData object has no attribute name: " + repr(item))

    def nullify(self, field):
        """
        Resets a value to its null value from :param METADATA_NULL_VALUES;
        Calling any of the three quantity collections (creators, identifiers, internal_identifiers) will result in all
        elements of that type being nullified.
        :param field:
        :return:
        """
        field_key = field.lower().strip()
        _data = object.__getattribute__(self, "_data")

        if field_key.lower() == "creators":
            for typ in CREATOR_CATEGORIES:
                try:
                    _data[typ] = OrderedDict()
                except KeyError:
                    pass
            return

        if field_key == "identifiers":
            for typ in EXTERNAL_EBOOK_ID_SCHEMA:
                try:
                    _data[typ] = OrderedDict()
                except KeyError:
                    pass
            return

        if field_key == "internal_identifiers":
            for typ in INTERNAL_EBOOK_ID_SCHEMA:
                try:
                    _data[typ] = OrderedDict()
                except KeyError:
                    pass
            return

        if field in _data:
            _data[field] = deepcopy(METADATA_NULL_VALUES[field])
            return

        raise KeyError("field : '{0}' with field_key: '{1}' not recognized.".format(field, field_key))

    # ----------------------------------------------------------------------------------------------------------------------
    #
    # - SPECIALIZED ACCESS METHODS START HERE
    #
    # ----------------------------------------------------------------------------------------------------------------------

    def get_identifiers(self):
        """
        Returns the identifiers as a dictionary of sets.
        The dict is small, and the penalty for using a reference where a copy is needed is large. Also, we don't want
        any manipulations of the returned dict to show up in the book.
        You can pass it back in using the set_identifiers method.
        For calibre emulation.
        :return identifiers_dict:
        """
        _data = object.__getattribute__(self, "_data")
        ids_dict = dict()

        for id_type in EXTERNAL_EBOOK_ID_SCHEMA:
            if id_type in _data:
                ids_dict[id_type] = set(_data[id_type].keys())
        return deepcopy(ids_dict)

    def get_internal_identifiers(self):
        """
        Return a copy of the internal identifiers dictionary of sets.
        The dict is small, and the penalty for using a reference where a copy is needed is large. Also, we don't want
        any manipulations of the returned dict to show up in the book.
        You can pass it back in using the set_internal_identifiers method.
        For calibre emulation.
        :return identifiers_dict:
        """
        _data = object.__getattribute__(self, "_data")
        ids_dict = dict()
        for id_type in INTERNAL_EBOOK_ID_SCHEMA:
            if id_type in _data:
                ids_dict[id_type] = set(_data[id_type].keys())
        return deepcopy(ids_dict)

    # copied from calibre
    @staticmethod
    def _clean_identifier(typ, val):
        """
        Attempts to tidy a type, value pair of identifiers
        :param typ: The type of the identifier
        :param val: The value of the identifier
        :return typ, val: Cleaned pair
        """
        if typ:
            typ = clean_id_key(typ)
        if val:
            val = clean_id_value(val)
        return typ, val

    def read_identifiers(self, identifiers):
        """
        Front end for the set_identifiers method.
        :param identifiers:
        :return:
        """
        return self.set_identifiers(identifiers)

    # copied from calibre
    def set_identifiers(self, identifiers):
        """
        Set all identifiers. Note that, if any of the identifiers mentioned in the :param identifiers: dict have already
        been set, this method will delete them.
        calibre compliant.
        :param identifiers: A dictionary of identifiers keyed by the types, valued with the identifiers - either as a
                            string, a set or an OrderedDict.
        :return:
        """
        _data = object.__getattribute__(self, "_data")

        cleaned = {clean_id_key(k): v for k, v in iteritems(identifiers) if k and v}
        for typ in cleaned:
            typ_stand = standardize_id_name(typ)

            # If standardization has nullified the type, then it will have been logged and we can continue
            if typ_stand is None:
                continue
            if typ_stand not in _data:
                _data[typ_stand] = OrderedDict

            # If the type is recognized, add it to _data
            ids = cleaned[typ]
            if isinstance(ids, six_string_types):
                ids = clean_id_value(ids)
                _data[typ_stand][ids] = None
            elif isinstance(ids, OrderedDict):
                _data[typ_stand] = deepcopy(ids)
            elif isinstance(ids, (list, tuple)):
                for id_val in ids:
                    _data[typ_stand][id_val] = None
            else:
                err_str = "Unable to add identifiers - format not recognized"
                err_str = default_log.log_variables(
                    err_str,
                    "ERROR",
                    ("typ", typ),
                    ("typ_stand", typ_stand),
                    ("ids", ids),
                    ("ids_type", type(ids)),
                )
                raise NotImplementedError(err_str)

    # copied from calibre
    def set_identifier(self, typ, val):
        """
        Add an identifier - if the value is None, deletes all the identifiers of that type.
        calibre compliant
        :param typ:
        :param val:
        :return:
        """
        typ, val = self._clean_identifier(typ, val)
        typ = standardize_id_name(typ)
        _data = object.__getattribute__(self, "_data")
        if typ is not None and typ in _data:
            if val is None:
                _data[typ] = OrderedDict()
            else:
                _data[typ][val] = None
        elif typ is not None and typ not in _data:
            _data[typ] = OrderedDict()
            _data[typ][val] = None
        elif typ is None:
            return
        else:
            raise NotImplementedError("This position should never be reached.")

    # copied from calibre
    def has_identifier(self, typ):
        """
        Tests to see if a type of identifier has been added.
        calibre compliant.
        :param typ:
        :return:
        """
        typ_stand = standardize_id_name(typ)
        if typ_stand is None:
            return False

        _data = object.__getattribute__(self, "_data")
        if typ_stand not in _data:
            return False
        return True if _data[typ_stand] else False

    def get_authors_copy(self):
        """
        Returns a copy of a list of all the author names.
        calibre compliant.
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        if "authors" in _data:
            author_list = [a for a in _data["authors"].keys()]
            return deepcopy(author_list)
        return []

    def get_creators_dump(self):
        """
        Used when adding creators to a title when adding to the database - returns a dictionary keyed with the
        creator_role and valued with a OrderedDict keyed with the
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        creators_dict = dict()
        for creator_role in CREATOR_CATEGORIES:
            if creator_role in _data:
                creators_dict[creator_role] = deepcopy(_data[creator_role])
        return creators_dict

    # ----------------------------------------------------------------------------------------------------------------------
    #
    # - SPECIALIZED METHODS TO ADD DATA START HERE

    def direct_add(self, key, value, key_check=True):
        """
        Directly add a value to the underlying _data dict.
        Allows bypassing all setattr data normalization - used when copying data in wholesale e.g. from the database.
        Do not use unless you know EXACTLY what you're doing.
        By default will raise a KeyError unless the key is already in _data. This is to add checking to a fairly
        dangerous method.
        :param value:
        :param key_check:
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        if key_check and key not in _data.keys():
            err_str = "Key not found in _data - consider sources of error"
            err_str = default_log.log_variables(err_str, "ERROR", ("key", key), ("value", value))
            raise KeyError(err_str)
        _data[key] = value

    # Todo: Check that the tuple is the right way round for calibre
    def add_cover(self, data, typ="path", cover_id=None):
        """
        Takes image data, followed by the type of data it is. Preforms some basic checks and adds it to the object,
        Cover tuples are of the form typ (generally the extension of the file) followed by data - the data the file
        is composed of.
        Note - open file handles are fragile and can be closed by return statements - if an open file handle is passed
        into this method it will be read into memory and the data included here. Dump it to disk and pass in a path
        instead?
        If you have open file handlers produced by a read process please include them in register_file_for_cleanup so
        that they can be properly closed after being added to the database.
        :param data:
        :param typ:
        """
        if isinstance(data, file):
            data = data.read()

        image_tuple = (typ, data)
        status, message = check_image_tuple(image_tuple)

        # Write the data directly into _data - to avoid a call to __setattr__
        _data = object.__getattribute__(self, "_data")

        if status:
            _data["cover_data"][image_tuple] = cover_id
        else:
            raise InputIntegrityError(message)

        self.register_file_for_cleanup(data)

    # Todo: Keep consistent with the cover
    def add_file(self, data, typ="path", file_id=None):
        """
        Takes some cover data - followed by the type of data it is. Adds it to the object.
        Cover tuples are of the form typ (generally the extension of the file) followed by data - the data the file
        is composed of.
        Note - open file handles are fragile and can be closed by return statements - if an open file handle is passed
        into this method it will be read into memory and the data included here. Dump it to disk and pass in a path
        instead?
        If you have open file handlers produced by a read process please include them in register_file_for_cleanup so
        that they can be properly closed after being added to the database.
        :param data:
        :param typ:
        :param file_id:
        """
        # Open file handles will probabl be closed when return is called with this metadata object - so read them into
        # memory to be safe
        if isinstance(data, file):
            data = data.read()

        file_tuple = (typ, data)

        _data = object.__getattribute__(self, "_data")
        _data["files"][file_tuple] = file_id

        self.register_file_for_cleanup(data)

    def record_path_and_file_name(self, file_path):
        """
        For metadata completeness and later analysis the original file path/name of a file is recorded.
        This is a convenience method to add both the name of the file and the path to the file in one method from the
        original path.
        File paths recorded here WILL NOT be added to the system - if you want them to be add them using the add_file
        method - which will record them in the form of a path type file tuple.
        :param file_path: The path to the original file - name will be derieved from this.
        :return:
        """
        object.__getattribute__(self, "_data")["filepath"].append(file_path)

        file_name = os.path.split(file_path)[1]
        object.__getattribute__(self, "_data")["filename"].append(file_name)

    def set_doc_type(self, doc_type):
        """
        Method that should be used to set the document type
        :param doc_type:
        :return:
        """
        doc_type = six_unicode(doc_type)
        if doc_type not in ALLOWED_DOC_TYPES:
            err_str = "Unable to find doc_type in ALLOWED_DOC_TYPES.\n"
            err_str += "doc_type: " + doc_type + "\n"
            raise InputIntegrityError(err_str)
        self.__setattr__("doc_type", doc_type)

    def add_creators(self, creators):
        """
        Takes a dictionary of creators keyed by their role in producing the work.
        Adds them to the right place.
        If the value is a string, test for the presence of an '&' - if there is one splitting the string down at that
        point. If there isn't one just add the whole string.
        If the value is an iterable working through it and adding all the values as dictionary keyed.
        :param creators:
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        creators = deepcopy(creators)

        for creator_role in creators:

            value = creators[creator_role]
            s_creator_role = standardize_creator_category(creator_role)

            if s_creator_role is None:
                err_str = "creator_role was standardized to None - so the creator couldn't be parsed"
                err_str = default_log.log_variables(err_str, "ERROR", ("creator_role", creator_role), ("value", value))
                raise InputIntegrityError(err_str)

            try:
                if isinstance(value, six_string_types):
                    # Try detecting the encoding and then re-encoding the string with that encoding
                    try:
                        value_encoding = force_encoding(value, verbose=False)
                        value = six_unicode(value, encoding=value_encoding)
                    except UnicodeDecodeError:
                        value = six_unicode(value, errors="ignore")
                    except TypeError:
                        # If the string is already unicode then just leave it
                        pass

                    # Remove any byte order marks that remain from the encoding guess - snip the first character
                    if value.startswith("\ufeff"):
                        value = value[1:]

                    # Filter for auto generated additions to the creators - abort if the creator is autogenerated
                    for creator_re in CREATOR_DROP_REGEX_SET:
                        if re.match(creator_re, value):
                            raise AutogeneratedCreator

                    # If & is present assume that we have a single creator
                    if "&" not in value:
                        if s_creator_role not in _data:
                            _data[s_creator_role] = OrderedDict()
                        if value not in _data[s_creator_role]:
                            _data[s_creator_role][value] = None
                        return
                    else:
                        value = string_to_authors(value)
                        value = [creator.strip() for creator in value]

                if s_creator_role not in _data:
                    _data[s_creator_role] = OrderedDict()
                for creator_name in value:
                    creator_name = six_unicode(creator_name)
                    if creator_name not in _data[s_creator_role]:
                        _data[s_creator_role][creator_name] = None

            except AutogeneratedCreator:
                continue

    def update_creators(self, creators_dict):
        """
        Update the internal creators store with a creators_dict
        :param creators_dict:
        :type creators_dict: A dictionary of OrderedDicts - keyed with the role of the creator in the work and valued
                             with an OrderedDict keyed with the name of the creator and valued with the id of that
                             creator on the database.
                             Assumes that the creator_role has already been standardized and is suitable for immedate
                             inclusion into the database.
        :return:
        """
        _data = object.__getattribute__(self, "_data")

        # Iterate through, updating all the creators
        for creator_role in creators_dict:
            _data[creator_role].update(creators_dict[creator_role])

    def add_identifiers(self, identifiers):
        """
        Takes a dictionary of identifiers keyed by their type. Adds them in.
        If the value is a string then adds it in directly. If the value is a set or other iterable iterates over it
        and adds them all in.
        :param identifiers:
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        identifiers = deepcopy(identifiers)

        for id_type in identifiers:

            value = identifiers[id_type]
            s_id_type = standardize_id_name(id_type)

            # If the id cannot be standardized, then we can't proceed.
            if s_id_type is None:
                err_str = "Unable to standardize identifier type"
                default_log.log_variables(err_str, "ERROR", ("id_type", id_type), ("identifiers", identifiers))
                continue

            # Checks to see if the identifier is a simple string - if it is then just store it
            if isinstance(value, six_string_types):
                value = six_unicode(value)

                # Creating the set to store the value if required
                if s_id_type not in _data:
                    _data[s_id_type] = OrderedDict()
                    _data[s_id_type][value] = None
                    return

                # If the id type already exists store the value in it and proceed
                _data[s_id_type][value] = None
                return

            # If the identifiers object isn't a base string, itterate over it and add every value to the set
            if s_id_type not in _data:
                _data[s_id_type] = OrderedDict()

            for id_val in value:
                id_val = six_unicode(id_val)
                _data[s_id_type][id_val] = None

    def add_internal_identifiers(self, identifiers):
        """
        Takes a dictionary of identifiers keyed by their type. Adds them in.
        If the value is a string
        :param identifiers:
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        identifiers = deepcopy(identifiers)

        for id_type in identifiers:

            value = identifiers[id_type]
            s_id_type = standardize_internal_id_name(id_type)

            # If the id cannot be standardized, then we can't proceed.
            if s_id_type is None:
                raise InputIntegrityError(None)

            # Checks to see if the identifier is a simple string - if it is
            if isinstance(value, six_string_types):
                value = six_unicode(value)

                # Creating the set to store the value if required
                if s_id_type not in _data:
                    _data[s_id_type] = set()
                    _data[s_id_type].add(value)
                    return

                # If the id type already exists store the value in it and proceed
                _data[s_id_type].add(value)
                return

            # If the identifiers object isn't a base string, itterate over it and add every value to the set
            if s_id_type not in _data:
                _data[s_id_type] = set()

            for id_val in value:
                id_val = six_unicode(id_val)
                _data[s_id_type].add(id_val)

    #
    # ----------------------------------------------------------------------------------------------------------------------
    # ----------------------------------------------------------------------------------------------------------------------
    #
    # - DISPLAY METHODS START HERE
    #
    # ----------------------------------------------------------------------------------------------------------------------

    def __unicode__(self):
        """
        Uses pretty print to provide a unicode representation of this class.
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        return pprint.pformat(_data)

    def __str__(self):
        """
        Calls unicode, and then safely encodes the result.
        :return:
        """
        return self.__unicode__().encode("utf-8")

    def __repr__(self):
        """
        Returns a safe representation of this object.
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        return pprint.saferepr(_data)

    def to_html(self):
        """
        Produces an html representation of this Metadata.
        :return html_string:
        """
        _data = object.__getattribute__(self, "_data")
        ans = []

        def format_creator_field_dict(field_dict, creator_role, html_ans):
            """
            Takes a dictionary of fields - formats it and adds it to ans
            """
            html_ans += [(_("Creator_Role"), six_unicode(creator_role))]
            for person in field_dict:
                html_ans += [(_("Creator"), six_unicode(person))]
            return html_ans

        def format_id_field_set(id_set, id_name, html_ans):
            """
            Takes a set of identifiers - formats it and adds it to ans
            """
            html_ans += [(_("Identifier Type"), six_unicode(id_name))]
            for identifier in id_set:
                html_ans += [("", identifier)]
            return html_ans

        for field in _data:

            creator_field = standardize_creator_category(field, logging=False)
            id_field = standardize_id_name(field, logging=False)
            internal_id_field = standardize_internal_id_name(field, logging=False)

            if creator_field is not None:
                ans = format_creator_field_dict(_data[field], creator_field, ans)
            elif id_field is not None:
                ans = format_id_field_set(_data[field], id_field, ans)
            elif internal_id_field is not None:
                ans = format_id_field_set(_data[field], internal_id_field, ans)

            # After considering specific cases, trying to match to general cases.
            elif isinstance(_data[field], OrderedDict):
                field_values = deepcopy(_data[field].keys())
                field_values = [six_unicode(value) for value in field_values]
                if _data[field].keys() is not None:
                    ans_str = " , ".join(field_values)
                    ans += [(_(field), ans_str)]
                else:
                    ans += [(_(field), "None")]

            elif isinstance(_data[field], set):
                field_value_set = deepcopy(_data[field])
                field_values = [six_unicode(value) for value in field_value_set]
                if field_values:
                    ans += [(_(field), field_values)]
                else:
                    ans += [(_(field), "None")]

            else:
                ans += [(_(field), _data[field])]

        for i, x in enumerate(ans):
            ans[i] = "<tr><td><b>%s</b></td><td>%s</td></tr>" % x
        return "<table>%s</table>" % "\n".join(ans)

    def format_series_index(self, val=None):
        """
        from calibre
        By default searches for a series index for the first series in the series OrderedDict - if one isn't found then
        returns a default value of 1.
        If a value is provided renders it in human readable form and returns it.
        :param val: default to None
        :return:
        """
        from LiuXin.utils.general_ops.human_readable import fmt_num

        if val is None:
            try:
                v = self.series_index[self.series.keys()[0]]
            except KeyError:
                v = 1
        else:
            v = val

        try:
            x = float(v)
        except (ValueError, TypeError):
            x = 1
        return fmt_num(x)

    def __nonzero__(self):
        return bool(self.title or self.author or self.comments or self.tags)

    # ------------------------------------------------------------------------------------------------------------------
    #
    # - METHODS TO GET INFORMATION ABOUT THE METADATA OBJECT START HERE
    #
    # ----------------------------------------------------------------------------------------------------------------------

    def __iter__(self):
        """
        Iterates over the _data keys.
        :return:
        """
        return iterkeys(object.__getattribute__(self, "_data"))

    @staticmethod
    def standard_field_keys():
        """
        Returns a frozenset of the keys of METADATA_NULL_VALUES
        """
        return frozenset(iterkeys(METADATA_NULL_VALUES))

    def user_metadata_keys(self):
        """
        Returns a set of the names of all user set metadata fields.
        """
        return frozenset(iterkeys(object.__getattribute__(self, "_data")["user_metadata"]))

    def all_field_keys(self):
        """
        All field keys known by this instance, even if their value is None
        """
        _data = object.__getattribute__(self, "_data")

        top_level_keys = frozenset(iterkeys(_data))
        external_identifier_keys = frozenset(iterkeys(_data["identifiers"]))
        internal_identifier_keys = frozenset(iterkeys(_data["internal_identifiers"]))
        creator_keys = frozenset(iterkeys(_data["creators"]))

        return_set = top_level_keys.union(external_identifier_keys)
        return_set = return_set.union(internal_identifier_keys)
        return_set = return_set.union(creator_keys)

        return return_set

    def all_set_fields(self):
        """
        Pass through method for all_non_none_fields.
        :return set_fields: A set of fields which have been set.
        """
        return self.all_non_none_fields()

    def all_non_none_fields(self):
        """
        Return a dictionary containing all non-None metadata fields, including
        the custom ones.
        :return set_fields: A set of fields which have been set.
        """
        set_fields = {}
        all_keys = self.all_field_keys()
        for key in all_keys:
            if self.is_null(key):
                set_fields[key] = self.get(key)

        return set_fields

    def is_null(self, field):
        """
        Checks against the default field value to see if the value is null.
        Returns True if the value isn't set, and False if it is.
        :param field:
        :return True/False:
        """
        try:
            null_val = METADATA_NULL_VALUES.get(field, None)
            val = getattr(self, field, None)
            return not val or val == null_val
        except:
            return False

    # ----------------------------------------------------------------------------------------------------------------------
    #
    # - COPY AND UPDATE METHODS START HERE
    #
    # ----------------------------------------------------------------------------------------------------------------------

    def dict_add(self, more_metadata):
        """
        Takes the _data from another MetaData class. Adds it to the current _data.
        Nothing fancy, and no collision detection.
        :param more_metadata: MetaData to be added to the current object.
        :return None: Chnages are purely internal
        """
        # Just a case of adding fields together, creating them where there don't exist
        _data = object.__getattribute__(self, "_data")
        new_data = more_metadata.get_data()
        for field in new_data:
            if field not in _data:
                _data[field] = new_data[field]
                continue

    def get_all_attr(self, copy=True):
        """
        Compatibility wrapper for the get_data function.
        Returns the raw _data dictionary for the MetaData object.
        By default returns a copy - can be overridden to return the actual _data.
        Use with care
        :param copy:
        :return:
        """
        return self.get_data(rtn_deepcopy=copy)

    def get_data(self, rtn_deepcopy=True):
        """
        Returns the raw _data dictionary for the MetaData object.
        By default returns a copy - can be overridden to return the actual _data.
        Use with care
        :param rtn_deepcopy: Boolean - should a copy be returned
        :return _data/deepcopy(_data):
        """
        _data = object.__getattribute__(self, "_data")
        if rtn_deepcopy:
            return deepcopy(_data)
        else:
            return _data

    def deepcopy_metadata(self):
        """
        Provides an unlinked copy of the current MetaData object.
        :return:
        """
        m = MetaData(None, None, None)
        object.__setattr__(m, "_data", deepcopy(object.__getattribute__(self, "_data")))
        return m

    def __deepcopy__(self):
        """
        Provides a handle for the deepcopy function from copy.
        :return:
        """
        return self.deepcopy_metadata()

    def smart_update(self, other, replace_metadata=False):
        """
        Smart merges the MetaData from one object into another.
        Other overrides the currently given data, unless the data is null.
        Where possible, data is added.
        :param other: Another instance of MetaData
        :param replace_metadata: If the data in other is not null, replace the current MetaData (where adding is
        possible ignore the option and overwrite - NOT RECOMMENDED).
        :return:
        """
        assert isinstance(other, MetaData)

        # Get the _data from another MetaData object. Filter for null values.
        _data = object.__getattribute__(self, "_data")
        default_data_keys = deepcopy(METADATA_NULL_VALUES.keys())
        new_data = other.get_all_attr(copy=True)
        new_data_fields = deepcopy(new_data.keys())

        # Copying over and removing the fields which aren't present in this objects _data
        for field in new_data_fields:
            if field not in default_data_keys:
                _data[field] = deepcopy(new_data[field])
                new_data.pop(field, None)

        # Copying over and replacing the fields which cannot be added to
        new_data_fields = deepcopy(new_data.keys())
        while len(new_data_fields) > 0:

            field = new_data_fields.pop()
            try:
                base_value = deepcopy(METADATA_NULL_VALUES[field])
            except KeyError as e:
                err_str = "smart_update metadata has failed.\nA field which should have been eliminated hasn't been.\n"
                err_str = default_log.log_exception(
                    err_str,
                    e,
                    "ERROR",
                    ("field", field),
                    ("new_data_fields", new_data_fields),
                )
                raise KeyError(err_str)

            if isinstance(base_value, dict):
                current_values = new_data[field]
                if replace_metadata:
                    _data[field] = current_values
                    continue
                for value in current_values:
                    _data[field][value] = new_data[field][value]

            elif base_value is None:
                if not other.is_null(field):
                    _data[field] = new_data[field]
                    continue

            elif isinstance(base_value, six_string_types):
                if not other.is_null(field):
                    _data[field] = new_data[field]
                    continue

            elif isinstance(base_value, set):
                if replace_metadata:
                    _data[field] = new_data[field]
                    continue
                _data[field].union(new_data[field])
                continue

            elif isinstance(base_value, list):
                values = deepcopy(new_data[field])
                if replace_metadata:
                    if values:
                        _data[field] = values
                for value in values:
                    if value not in _data[field]:
                        _data[field] += [
                            value,
                        ]

            else:
                err_str = "Unable to update given value.\nValue is of unrecognized type.\n"
                err_str = default_log.log_variables(
                    err_str,
                    "ERROR",
                    ("field", field),
                    ("new_data[field]", new_data[field]),
                )
                raise NotImplementedError(err_str)

        assert len(new_data_fields) == 0

    def clean(self):
        """
        Make sure that the title, creator and tags are in title case.
        :return:
        """
        from LiuXin.utils.libraries.titlecase import titlecase

        def title_case_rekey(target_dict):
            """
            Transform all the keys of a dictionary into title case.
            :param target_dict: Should be an OrderedDict
            :return:
            """
            new_dict = OrderedDict()
            for k, v in target_dict:
                new_dict[titlecase(k)] = v
            return new_dict

        def isbn_check_rekey(target_dict):
            """
            Transform the isbn keys of a dictionary,
            :param target_dict:
            :return:
            """
            new_dict = OrderedDict()
            for k, v in target_dict:
                new_dict[check_isbn(k)] = v
            return new_dict

        # Make sure all the creator names are in title case
        _data = object.__getattribute__(self, "_data")
        for creator_type in CREATOR_CATEGORIES:
            _data[creator_type] = title_case_rekey(_data[creator_type])

        # Make sure the title is in title case
        _data["title"] = titlecase(_data["title"])

        _data["tags"] = title_case_rekey(_data["tags"])

        if "isbn10" in _data.keys():
            _data["isbn10"] = isbn_check_rekey(_data["isbn10"])

    # ----------------------------------------------------------------------------------------------------------------------
    #
    # - METHODS TO INTERACT WITH USER METADATA START HERE
    #
    # ----------------------------------------------------------------------------------------------------------------------

    def get_all_user_metadata(self, make_copy):
        """
        Return a dict containing all the custom field metadata associated with the book.
        Copied from calibre
        :param make_copy:
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        user_metadata = _data["user_metadata"]
        if not make_copy:
            return user_metadata
        res = {}
        for k in user_metadata:
            res[k] = deepcopy(user_metadata[k])
        return res

    # ----------------------------------------------------------------------------------------------------------------------
    #
    # - INTERACTION METHODS WITH THE DATABASE START HERE
    #
    # ----------------------------------------------------------------------------------------------------------------------

    def from_title_row(self, title_row):
        """
        Takes a title row from the database. Uses it to populate all the metadata associated with that row.
        All data is deleted before the new data is copied in.
        Some fields are not populated.
        All comments are just stored in notes.
        All imprints are just stored as publishers (though an attempt is made after to work out which is which).
        Some fields are flat out ignored.
        :param title_row: A Row
        :return:
        """
        _data = object.__getattribute__(self, "_data")
        db = title_row.db
        title_row_collection = RowCollection(title_row)

        # Loading the title sections
        title_row_dict = title_row_collection["titles"][0]
        _data["title"] = title_row_dict["title"]
        _data["title_sort"] = title_row_dict["title"]
        _data["wordcount"] = title_row_dict["title_wordcount"]
        _data["pubdate"] = title_row_dict["title_pubdate"]

        # Transfer tables which have a standard interface (one column needed from each - associate the name of that
        # column with the id of the entry in that table)
        main_tables = deepcopy(db.get_categorized_tables()["main"])
        standard_tables = [
            "genres",
            "notes",
            "publishers",
            "series",
            "synopses",
            "subjects",
            "tags",
        ]

        for table in standard_tables:

            standard_rows = title_row_collection[table]
            standard_display_column = db.get_display_column(table)
            for standard_link in standard_rows:
                dis_value = standard_link[standard_display_column]
                if dis_value not in _data[table]:
                    _data[table][dis_value] = standard_link

        creator_rows = title_row_collection["creators"]
        for creator_link in creator_rows:
            creator_type = creator_link["creator_title_link_type"]
            if creator_type is None:
                wrn_str = "Unable to match creator type.\nDefaulting to author.\n"
                default_log.log_variables(
                    wrn_str,
                    "WARN",
                    ("creator_link['creator_id']", creator_link["creator_id"]),
                )
            creator_name = creator_link["creator"]
            creator_type = standardize_creator_category(creator_type)
            if creator_type in _data:
                _data[creator_type][creator_name] = creator_link
            elif creator_type not in _data:
                _data[creator_type] = OrderedDict()
                _data[creator_type][creator_name] = creator_link
            else:
                raise LogicalError
        main_tables.remove("creators")

        identifier_rows = title_row_collection["identifiers"]
        for id_link in identifier_rows:
            id_type = id_link["identifier_type"]
            id_value = id_link["identifier"]
            external_id_type = standardize_id_name(id_type)
            internal_id_type = standardize_internal_id_name(id_type)

            # Preforming sanity checks on the claimed values
            if external_id_type is None and internal_id_type is None:
                err_str = "Unable to normalize id name.\n"
                err_str += "Consider sources of error.\n"
                err_str += "id_type: " + six_unicode(id_type) + "\n"
                err_str += "id_value: " + six_unicode(id_value) + "\n"
                err_str += "id_row: " + six_unicode(id_link) + "\n"
                raise DatabaseIntegrityError(err_str)
            elif external_id_type is not None and internal_id_type is None:
                final_id_type = external_id_type
            elif external_id_type is None and internal_id_type is not None:
                final_id_type = internal_id_type
            elif external_id_type is not None and internal_id_type is not None:
                err_str = "Identifier matched of being both internal and external type.\n"
                err_str += "Consider sources of error.\n"
                err_str += "external_id_type: " + six_unicode(external_id_type) + "\n"
                err_str += "internal_id_type: " + six_unicode(internal_id_type) + "\n"
                err_str += "id_type: " + six_unicode(id_type) + "\n"
                err_str += "id_value: " + six_unicode(id_value) + "\n"
                err_str += "id_row: " + six_unicode(id_link) + "\n"
                raise InputIntegrityError(err_str)

            if final_id_type in _data:
                _data[final_id_type].add(id_value)
            elif final_id_type not in _data:
                _data[final_id_type] = set()
                _data[final_id_type].add(id_value)

        lang_rows = title_row_collection["languages"]
        if len(lang_rows) > 0:
            lang_row = lang_rows[0]
            _data["language"] = lang_row["language"]
        for lang_link in lang_rows:
            lang_name = lang_link["language"]
            _data["languages_available"][lang_name] = lang_link

        # If an entry is below the top level of the publishers table, it's considered an imprint.
        pub_rows = title_row_collection["publishers"]
        for pub_link in pub_rows:
            pub_name = pub_link["publisher"]
            pub_parent = pub_link["publisher_parent"]
            if pub_parent is None or pub_parent.lower() == "none":
                _data["imprints"][pub_name] = pub_link
            else:
                _data["publishers"][pub_name] = pub_link

        # The series rows are loaded as normal. The series index is given for the position of the title in the first
        # series it's linked to.
        series_rows = title_row_collection["series"]
        if len(series_rows) > 0:
            main_series_row = series_rows[0]
            _data["series_index"] = main_series_row["series_title_link_priority"]

    # Todo: ONce finalize has been called all the public methods of CHANGING the data should go away
    def finalize(self):
        """
        Method called at the end of adding metadata - preforms cleans functions and tries to standardize the metadata.
        Note - any id information may be blanked.
        :return: None - All changes are internal
        """
        _data = object.__getattribute__(self, "_data")

        # SERIES
        # If metadata has been written from calibre then there should be a calibre_series attribute and a
        # calibre_series_index attribute set. Process these two into the series structure
        # In order to set the series properly in this metadata object both the series name and the series position must
        # be known at the same time (to make sure that the index is being set for the right series).
        # During metadata read this is not always true - the series_index might be found before the series -so
        # storing them both as explicitly calibre things, and then combining them at the end
        # Todo: Make series_name a unique key
        # Todo: Deal with the case where there is a LiuXin AND a calibre series structure
        if "calibre_series" in _data and "calibre_series_index" in _data:

            series_name = _data["calibre_series"]
            series_index = _data["calibre_series_index"]

            _data["series"][series_name] = None
            _data["series_index"][series_name] = series_index

        elif "calibre_series" in _data and "calibre_series_index" not in _data:

            series_name = _data["calibre_series"]
            _data["series"][series_name] = None

        elif "calibre_series" not in _data and "calibre_series_index" in _data:

            err_str = "calibre_series_index was found - but not calibre_series."
            raise NotImplementedError(err_str)
        # ------

        # TITLE
        # If a calibre_title or a calibre_title_sort is present, then prefer the calibre variables over the regular one
        if "calibre_title" in _data:
            _data["title"] = _data["calibre_title"]
            del _data["calibre_title"]

        if "calibre_title_sort" in _data:
            _data["title_sort"] = _data["calibre_title_sort"]
            del _data["calibre_title_sort"]
        # -----

        # CREATORS
        # Filter the creators to remove any Unknowns
        # Todo: Drop unknowns in any language
        # Todo: Standardize language to lang code
        for creator_role in CREATOR_CATEGORIES:
            for key in _data[creator_role].iterkeys():
                if key.lower() == "unknown":
                    del _data[creator_role][key]

        # TAGS
        # If any tags are found to have a semi-colon in them then splits them down into individual tags
        # If there is a semi-colon in the tags field then the field is split down into individual tags - discarding
        # any id data stored in the OrderedDict's values
        # Todo: Make a central standardize_tag method
        new_tags_dict = OrderedDict()
        old_tags_dict = _data["tags"]
        for tag in old_tags_dict:
            split_tags = tag.split(";")
            if len(split_tags) == 1:
                new_tags_dict[standardize_tag(tag)] = old_tags_dict[tag]
            elif len(split_tags) > 1:
                for new_tag in split_tags:
                    new_tags_dict[standardize_tag(new_tag)] = None
            else:
                raise NotImplementedError("split on a string should never produce a 0 length list")
        _data["tags"] = new_tags_dict

        # Todo: After finalize is called it should be much harder to actually change the metadata object
        # Todo: Detect if title sort has been set and set it if it hasn't automatically

        return self

    # Todo: Replace all with the is_null meth
    def to_calibre(self):
        """
        Returns a calibreMetaData version of this metadata object.
        :return:
        """
        _data = object.__getattribute__(self, "_data")

        # TITLE
        calibre_md = calibreMetadata(title=self.title, authors=None)

        # AUTHORS
        # If there are both authors and editors then the editors go first
        lx_editors = self.editors
        if lx_editors:
            calibre_md.authors = self.editors.keys() + self.authors.keys()
        else:
            calibre_md.authors = self.authors.keys()

        # AUTHOR SORT
        cs = self.creator_sort
        calibre_md.author_sort = cs if cs else authors_to_sort_string(calibre_md.authors)

        # COMMENTS
        # Includes the synopsis as it seems to be the best place to store it
        comments_vals = self.comments.keys() + self.synopses.keys()
        calibre_md.comments = ", ".join(comments_vals)

        # COVER DATA
        cover_data = self.cover_data
        if cover_data:
            calibre_md.cover_data = cover_data.keys()[0]

        # IDENTIFIERS
        # If not null transfer the first identifier of each type over to the new metadata object
        for id_type in EXTERNAL_EBOOK_ID_SCHEMA.union(INTERNAL_EBOOK_ID_SCHEMA):
            type_ids = self.__getattr__(id_type)
            if type_ids:
                calibre_md.set(field=id_type, val=type_ids.keys()[0])

        # LANGUAGES
        calibre_md.languages = self.languages

        # PUBDATE
        calibre_md.pubdate = self.pubdate

        # PUBLISHER
        publisher = self.publisher
        if publisher:
            calibre_md.publisher = publisher.keys()[0]

        # RATINGS
        if "calibre" in _data["ratings"]:
            calibre_md.rating = _data["ratings"]["calibre"]

        # SERIES AND SERIES INDEX
        series = self.series
        if series:
            md_series = series.keys()[0]
            calibre_md.series = md_series

            if md_series in self.series_index:
                calibre_md.series_index = self.series_index[md_series]

        # TAGS
        calibre_md.tags = self.tags.keys() + self.subject.keys()

        # TTITLESORT
        calibre_md.titlesort = self.titlesort

        return calibre_md

    def __del__(self):
        """
        Makes sure that all outstanding objects are properly closed.
        :return:
        """
        self.close_cleanup_files()

        # -------------------
        # SHUT ALL OPEN FILES
        _data = object.__getattribute__(self, "_data")

        file_tuples = _data["files"].keys()
        for file_tuple in file_tuples:
            try:
                file_tuple[1].close()
            except AttributeError:
                pass

        cover_tuples = _data["cover_data"]
        for cover_tuple in cover_tuples:
            try:
                cover_tuple[1].close()
            except AttributeError:
                pass
        # -------------------

    def register_file_for_cleanup(self, file_pointer):
        """
        Register that there might be an open file object.
        :return:
        """
        open_files = object.__getattribute__(self, "_files_for_cleanup")
        open_files.append(file_pointer)

    def close_cleanup_files(self):
        """
        Try and close all the files registered as open in the cleanup files.
        :return:
        """
        open_files = object.__getattribute__(self, "_files_for_cleanup")
        for file_pointer in open_files:
            try:
                file_pointer.close()
            except AttributeError:
                pass

    # ------------------------------------------------------------------------------------------------------------------
    #
    # - HELP METHODS START HERE
    #
    # ----------------------------------------------------------------------------------------------------------------------

    @staticmethod
    def explain_field(key):
        """
        Returns an explanation for the given key.
        :param key:
        :return explanation:
        """
        if key in METADATA_EXPLANATIONS:
            return METADATA_EXPLANATIONS[key]

        raise ValueError("No available explanation.")


class MetaInformation(MetaData):
    pass
